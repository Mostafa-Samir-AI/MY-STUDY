---
author: Mostafa Samir Ali
tags:
  - "#AI"
  - Machine_learning
---


# linear regression
- Linear Regression describes a linear relationship between an independent variable and the dependent variable.
- The main idea is to predict the best fit line with the help of given data points.
- the line equation is 
$$ Y = a_0 + a_1 .X $$
- where 
1.  $Y$ : target
2.  $a_0$ : coefficient where the line start to plot
3.  $a_1$ : slope of the line (m)
4.  $X$ : features given

- ***the goal*** is to find the best values for $a_0$ and $a_1$ that fits through data
>[!note] ## Hint
>to find the best $a_0$ and $a_1$ we wil go through the process of gradient descent and cost function 
> - look at [[cost function]] , [[gradient descent]] 


-  cost function for linear regression (M.S.E)
$$Cost\ Function\ (J) = \frac{1}{n}\sum_{i = 0}^{n} \left(y^i - (mx^i + b)\right)^2$$
![[Pasted image 20240429185840.png]]


# linear regression steps
1. we suppose that $w$ and $b$ are random values
2. we calculate all inputs multiplied by weights $w_1.x_1 + w_2.x_2 +\dots w_n.x_n$ 
3. fitting the line based on our inputs in the data
4. measure error by using cost function
5. updating values using gradient descent 
6. repeat until the error is too low and the values updated are close to the previous values

### applying gradient descent for linear regression

![[Pasted image 20240429190307.png]]


<details>
<summary>
    <font size='3', color='darkgreen'><b>Hints</b></font>
</summary>
    <p>
    <ul>
        <li>Try $w = 200$ and $b = 100$ </li>
    </ul>
    </p>

# practical 
- after cleaning the data we are now ready to proceed in the machine learning process
- we will follow some steps
	1. measure correlation
	2. one hot encoder
	3. split the data into train and test data
	4. model 
	5. measuring error

## 1. measure correlation
- look for [[correlation and regression]]
## 2. One hot encoder
- look for [[Encoders]]
## 3. split the data
- we now are able to split the data into training data and testing data
- the user defines the ratio of both training and testing data according to the total size of the data
- usually we split the data 80 : 20
	- 80 ==> training
	- 20 ==> testing
- steps:-
	1. we split the features and the target away from each other
	2. split the data to train and test data
* code practice
```python
# steps to split the data

## seperate the feature data from the target data
X = data.drop('price' ,axis = 1).values     # axis = 1 ==> column / values ==> to get the vales
y = data["price"].values

## import train_test_split function from sklean
from sklearn.model_selection import train_test_split

## splitting the data
x_train , x_test , y_train , y_test = train_test_split(X , y , test_size = 0.2)
```

## 4. model
- choosing the model according to the nature of the data
- in this notebook we choose Linear Regression 
- so , the procedure is 
	1. import the model from sklearn and declare an object
	2. train the model
	3. make prediction
#### import the model
- we should import the model from sklearn library , linear model module
```python
# import model 
from sklearn.linear_model import LinearRegression

# make an object of the model
model = LinearRegression()
```
#### Train the model
- the model will be trained on the training dataset we separated from original dataset
- the model will be trained on **x_train** and **y_train** 

```python
# training the model
model.fit(x_train , y_train)
```

#### making a prediction
- now , let the model make a prediction of the data
- the model will predict the value of the target 
* the procedure for prediction process :-
		- pass **x_test** to the model
		- the model give a prediction , the result will be **y_pred**  
		- in the error measure **y_test** will be compared to **y_pred** to see how much difference between them and how the model preformed
		- predict(x_test) ---> y_pred 

```python
# making prediction
y_pred = model.predict(x_test)
```

## 5. Measuring error
- we use many techniques in measuring errors [[cost function]]
- in this note book we will use M.S.E 
- steps:-
	- import the mean_square_error from sklearn.metrics
	- measure the error between **y_pred** , **y_test**
#### error measure code

```python
# importing the mean_square_error
from sklearn.metrics import mean_square_error

# measure the error
mean_square_error(y_pred , y_test)
```

 