---
author: Mostafa Samir Ali
tags:
  - AI
  - Machine_learning
---

# Polynomial regression
- Polynomial regression is a type of regression analysis used in statistics and machine learning when the relationship between the independent variable (input) and the dependent variable (output) **is not linear**.
- When the relationship between the variables is <u>better represented by a curve rather than a straight line</u>, ==polynomial regression== can capture the non-linear patterns in the data.

# how does polynomial regression work ?
- If we observe closely then we will realize that to evolve from linear regression to polynomial regression. 
- We are just supposed to ==add the higher-order terms of the dependent features in the feature space==.
- When the relationship is non-linear, a polynomial regression model introduces higher-degree polynomial terms.

* **Equation**
$$
y = \theta_0 + \theta_1 x + \theta_2 x^2 + \theta_3 x^3 + \cdots + \theta_n x^n
$$

or

$$
y = \sum_{i=0}^{n} \theta_i x^i
$$


### ****Advantages of using Polynomial Regression****

- A broad range of functions can be fit under it.
- Polynomial basically fits a wide range of curvatures.
- Polynomial provides the best approximation of the relationship between dependent and independent variables.

### ****Disadvantages of using Polynomial Regression****Â 

- These are too sensitive to outliers.
- The presence of one or two [outliers](https://www.geeksforgeeks.org/machine-learning-outlier/) in the data can seriously affect the results of nonlinear analysis.
- In addition, there are unfortunately fewer model validation tools for the detection of outliers in nonlinear regression than there are for linear regression.

# Implementation
#### 1. polynomial Features
```python
'''
Expected 2D array, got 1D array instead:
array=[ 1  2  3  4  5  6  7  8  9 10].
Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.

- when transforming the features --> we transform only the x-values not the y
'''

# converting X to polynomail feature
from sklearn.preprocessing import PolynomialFeatures

ply = PolynomialFeatures(degree = 3)
poly_features = ply.fit_transform(x.reshape(-1,1))
```
#### 2. Linear regression
```python
# import the model
from sklearn.linear_model import LinearRegression
model = LinearRegression()

# training the model
model.fit(poly_features , y)

# predictions
y_pred=model.predict(poly_features)
```

> [!NOTE] ## NOTE
> - when predicting data in the polynomial regression , we need to convert the data int a polynomial data